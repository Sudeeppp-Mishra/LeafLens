{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNayEppw6c+etkzGibaB+p+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sudeeppp-Mishra/LeafLens/blob/main/LeafLens_Train_on_DataSets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeafLens: AI-Based Plant Disease Detection\n",
        "\n",
        "LeafLens classifies plant leaf images into healthy or diseased categories.\n",
        "We use a pretrained ResNet18 model (transfer learning) for accuracy and faster training.\n",
        "\n",
        "**Libraries used:**\n",
        "- PIL / OpenCV / NumPy: Image loading and preprocessing\n",
        "- PyTorch / Torchvision: Model training and evaluation\n",
        "- Matplotlib: Visualization of metrics\n",
        "- PySide6 / pyttsx3 / gTTS: GUI + audio output (later integration)\n",
        "\n",
        "**Dataset:** PlantVillage (Image Classification)  \n",
        "**Platform:** Google Colab (GPU)"
      ],
      "metadata": {
        "id": "QdoIfBU02_pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why GPU?\n",
        "\n",
        "Deep learning models require heavy computation.  \n",
        "Using GPU in Colab speeds up training significantly."
      ],
      "metadata": {
        "id": "dxngTJlc342E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive\n",
        "\n",
        "Accessing PlantVillage dataset stored in Google Drive.  \n",
        "This avoids repeated uploads and keeps large datasets organized."
      ],
      "metadata": {
        "id": "8owmyFw938td"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "doSPHUp6jDVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdbf00d0-0457-4c5b-a874-bb963cddb9e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required Libraries\n",
        "\n",
        "- torch, nn, optim: Core deep learning\n",
        "- torchvision: Pretrained models and transforms\n",
        "- cv2: OpenCV for image preprocessing\n",
        "- PIL: For PyTorch compatibility\n",
        "- matplotlib, numpy: Visualization & arrays\n",
        "- os: File management"
      ],
      "metadata": {
        "id": "lXoyeV3PG6Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "n4rC4f0g4NkD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check GPU\n",
        "\n",
        "We confirm if GPU is available.  \n",
        "Training on GPU is much faster than CPU."
      ],
      "metadata": {
        "id": "X3oLLce_HPsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6oTssV8G8z0",
        "outputId": "6e3e4fda-bef1-4459-f8b7-12e411b92add"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Path\n",
        "\n",
        "Set path to PlantVillage dataset on Google Drive.\n",
        "Each subfolder corresponds to a class label."
      ],
      "metadata": {
        "id": "IlByVJX8HfhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/datasets/PlantVillage\"\n",
        "print(\"Classes found:\", os.listdir(data_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPsqNeDUHSW3",
        "outputId": "c3ee159a-3b19-4d90-a3db-3f79c90b19bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes found: ['Tomato_healthy', 'PlantVillage', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato_Leaf_Mold', 'Potato___Early_blight', 'Tomato_Septoria_leaf_spot', 'Potato___Late_blight', 'Tomato_Early_blight', 'Tomato__Target_Spot', 'Pepper__bell___healthy', 'Tomato__Tomato_mosaic_virus', 'Tomato_Bacterial_spot', 'Potato___healthy', 'Pepper__bell___Bacterial_spot', 'Tomato_Late_blight']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Preprocessing & Augmentation\n",
        "\n",
        "**Why:**  \n",
        "- Resize images to 224x224 (ResNet input requirement)  \n",
        "- Normalize pixel values for stable training  \n",
        "- Data augmentation (rotation, flip) improves generalization  \n",
        "- OpenCV is used for preprocessing (denoising, resizing)  \n",
        "- PIL is used to convert images into format compatible with PyTorch transforms"
      ],
      "metadata": {
        "id": "uiPKumztHrJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PlantVillageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.classes = sorted(os.listdir(root_dir))\n",
        "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "\n",
        "        # Load image paths and labels\n",
        "        for cls in self.classes:\n",
        "            cls_folder = os.path.join(root_dir, cls)\n",
        "            for img_name in os.listdir(cls_folder):\n",
        "                img_path = os.path.join(cls_folder, img_name)\n",
        "                self.images.append(img_path)\n",
        "                self.labels.append(self.class_to_idx[cls])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Read image with OpenCV\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            # Handle unreadable image\n",
        "            img = np.zeros((224,224,3), dtype=np.uint8)\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (224,224))\n",
        "        img = cv2.GaussianBlur(img, (3,3), 0)  # optional denoising\n",
        "\n",
        "        # Convert to PIL Image for transforms\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "UZ7vXcaZHiUD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training & Validation Transforms\n",
        "\n",
        "- Training: Random rotation and horizontal flip for augmentation  \n",
        "- Validation: Only resizing and normalization  \n",
        "- Normalization values are same as ImageNet (used by pretrained ResNet)"
      ],
      "metadata": {
        "id": "CuTMzYUVIJE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "6_W-f3NzHt5l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset using Custom Class\n",
        "\n",
        "- Handles OpenCV reading + PIL conversion  \n",
        "- Applies transforms for training and validation"
      ],
      "metadata": {
        "id": "w1l9-tRhIlyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = PlantVillageDataset(root_dir=data_dir, transform=train_transforms)\n",
        "\n",
        "num_classes = len(full_dataset.classes)\n",
        "class_names = full_dataset.classes\n",
        "\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Classes:\", class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tucq7E-eINHn",
        "outputId": "1b2d6568-f251-4680-ecad-870bf5bcf46f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 16\n",
            "Classes: ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'PlantVillage', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Dataset\n",
        "\n",
        "- 80% training  \n",
        "- 20% validation  \n",
        "- Ensures model is evaluated on unseen images"
      ],
      "metadata": {
        "id": "Fg9yvD7zIwYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Assign correct transforms\n",
        "train_dataset.dataset.transform = train_transforms\n",
        "val_dataset.dataset.transform = val_transforms"
      ],
      "metadata": {
        "id": "0L6D34jhIorG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader\n",
        "\n",
        "- Loads batches efficiently  \n",
        "- Shuffles training data for better convergence"
      ],
      "metadata": {
        "id": "mScgoieXI499"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "PnGv0tRNIynn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet18 Model\n",
        "\n",
        "- Pretrained on ImageNet  \n",
        "- Replace final fully connected layer for our number of classes  \n",
        "- Transfer learning speeds up training and improves accuracy"
      ],
      "metadata": {
        "id": "s1QNFk0kJRtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liBSZOUyI753",
        "outputId": "32db3daf-5f84-439f-a32b-0885a51091d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 69.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function & Optimizer\n",
        "\n",
        "- CrossEntropyLoss for multi-class classification  \n",
        "- Adam optimizer adapts learning rate for faster convergence"
      ],
      "metadata": {
        "id": "dlw9KHh2Jd3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "y06e2wlgJURF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V12ClWoXJhSe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}